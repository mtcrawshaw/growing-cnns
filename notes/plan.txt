Cards:

- Unit test case for growth step

Merge to master

- Identity initialization for new layers
- Unit test case for function preservation after growth

Merge to master

- Add growth speed parameter
- Unit test cases for growth step for each growth speed (linear, exponential)

Merge to master

- Add notes to README
- Fix argument structure for training/evaluation

Merge to master


Future stuff:
Add ImageNet + other datasets
Parallelize across multiple GPUs
Add different block types
Dynamic batch sizes across growth steps using model size estimation (https://github.com/jacobkimmel/pytorch_modelsize)

Features:
3 point growth methods (options: vanilla, freeze old layers for a time, different learning rates for old and new layers, and sliding weighted average for methods 2, 3)
1 network growth method for point method 1, 3 network growth methods for point method 2, 2 network growth methods for point method 3
Convolution, Resnet basic, Resnet bottleneck, Densenet, Inception module
Dropfilter, Dropblock, stochastic depth, drop path for option 3
Early stopping, fixed number of epochs, ?


